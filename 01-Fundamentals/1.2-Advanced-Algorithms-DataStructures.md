# 🧮 1.2 ADVANCED ALGORITHMS AND DATA STRUCTURES

> *"The art and science of efficient problem-solving through optimal data organization and algorithmic design"*

---

## 🎯 LEARNING OBJECTIVES

By the end of this section, you will be able to:
- **🏗️ Design and implement** fundamental data structures from scratch
- **⚡ Analyze algorithmic complexity** using Big O, Omega, and Theta notations
- **🔍 Choose optimal algorithms** for specific problem domains
- **🧩 Apply algorithmic paradigms** to solve complex computational problems
- **📊 Optimize performance** through appropriate data structure selection
- **🎨 Design custom algorithms** for novel problem scenarios

---

## 📚 1. FUNDAMENTAL DATA STRUCTURES

### 📋 **1.1 Linear Data Structures**

#### **🔗 Arrays and Dynamic Arrays**

**Static Arrays**
```pseudocode
STRUCTURE StaticArray
    data: ARRAY[size] of ElementType
    size: INTEGER
    
    FUNCTION get(index)
        IF index < 0 OR index >= size THEN
            THROW IndexOutOfBoundsException
        END IF
        RETURN data[index]
    END FUNCTION
    
    FUNCTION set(index, value)
        IF index < 0 OR index >= size THEN
            THROW IndexOutOfBoundsException
        END IF
        data[index] ← value
    END FUNCTION
END STRUCTURE
```

**Dynamic Arrays (Resizable)**
```pseudocode
STRUCTURE DynamicArray
    data: POINTER to ARRAY of ElementType
    size: INTEGER
    capacity: INTEGER
    
    FUNCTION DynamicArray()
        capacity ← 4
        size ← 0
        data ← ALLOCATE_MEMORY(capacity * SIZEOF(ElementType))
    END FUNCTION
    
    FUNCTION add(element)
        IF size = capacity THEN
            resize()
        END IF
        data[size] ← element
        size ← size + 1
    END FUNCTION
    
    FUNCTION resize()
        old_capacity ← capacity
        capacity ← capacity * 2
        new_data ← ALLOCATE_MEMORY(capacity * SIZEOF(ElementType))
        
        FOR i ← 0 TO size - 1 DO
            new_data[i] ← data[i]
        END FOR
        
        DEALLOCATE_MEMORY(data)
        data ← new_data
    END FUNCTION
END STRUCTURE
```

**Time Complexities:**
- Access: O(1)
- Search: O(n)
- Insertion: O(1) amortized, O(n) worst case
- Deletion: O(n)

#### **🔗 Linked Lists**

**Singly Linked List**
```pseudocode
STRUCTURE Node
    data: ElementType
    next: POINTER to Node
END STRUCTURE

STRUCTURE SinglyLinkedList
    head: POINTER to Node
    size: INTEGER
    
    FUNCTION add(element)
        new_node ← CREATE Node
        new_node.data ← element
        new_node.next ← head
        head ← new_node
        size ← size + 1
    END FUNCTION
    
    FUNCTION remove(element)
        IF head = NULL THEN RETURN false
        
        IF head.data = element THEN
            head ← head.next
            size ← size - 1
            RETURN true
        END IF
        
        current ← head
        WHILE current.next ≠ NULL DO
            IF current.next.data = element THEN
                current.next ← current.next.next
                size ← size - 1
                RETURN true
            END IF
            current ← current.next
        END WHILE
        
        RETURN false
    END FUNCTION
END STRUCTURE
```

**Doubly Linked List**
```pseudocode
STRUCTURE DoublyNode
    data: ElementType
    next: POINTER to DoublyNode
    prev: POINTER to DoublyNode
END STRUCTURE

STRUCTURE DoublyLinkedList
    head: POINTER to DoublyNode
    tail: POINTER to DoublyNode
    size: INTEGER
    
    FUNCTION addFirst(element)
        new_node ← CREATE DoublyNode
        new_node.data ← element
        new_node.next ← head
        new_node.prev ← NULL
        
        IF head ≠ NULL THEN
            head.prev ← new_node
        ELSE
            tail ← new_node
        END IF
        
        head ← new_node
        size ← size + 1
    END FUNCTION
    
    FUNCTION addLast(element)
        new_node ← CREATE DoublyNode
        new_node.data ← element
        new_node.next ← NULL
        new_node.prev ← tail
        
        IF tail ≠ NULL THEN
            tail.next ← new_node
        ELSE
            head ← new_node
        END IF
        
        tail ← new_node
        size ← size + 1
    END FUNCTION
END STRUCTURE
```

#### **📥 Stacks (LIFO - Last In, First Out)**

```pseudocode
STRUCTURE Stack
    data: DynamicArray
    
    FUNCTION push(element)
        data.add(element)
    END FUNCTION
    
    FUNCTION pop()
        IF isEmpty() THEN
            THROW StackUnderflowException
        END IF
        element ← data.get(data.size - 1)
        data.removeAt(data.size - 1)
        RETURN element
    END FUNCTION
    
    FUNCTION peek()
        IF isEmpty() THEN
            THROW StackUnderflowException
        END IF
        RETURN data.get(data.size - 1)
    END FUNCTION
    
    FUNCTION isEmpty()
        RETURN data.size = 0
    END FUNCTION
    
    FUNCTION size()
        RETURN data.size
    END FUNCTION
END STRUCTURE
```

**Applications:**
- Function call management
- Expression evaluation
- Undo operations
- Backtracking algorithms

#### **📤 Queues (FIFO - First In, First Out)**

**Simple Queue**
```pseudocode
STRUCTURE Queue
    data: DynamicArray
    front: INTEGER
    rear: INTEGER
    size: INTEGER
    
    FUNCTION Queue()
        front ← 0
        rear ← -1
        size ← 0
    END FUNCTION
    
    FUNCTION enqueue(element)
        rear ← (rear + 1) MOD data.capacity
        data.set(rear, element)
        size ← size + 1
    END FUNCTION
    
    FUNCTION dequeue()
        IF isEmpty() THEN
            THROW QueueUnderflowException
        END IF
        element ← data.get(front)
        front ← (front + 1) MOD data.capacity
        size ← size - 1
        RETURN element
    END FUNCTION
    
    FUNCTION isEmpty()
        RETURN size = 0
    END FUNCTION
END STRUCTURE
```

**Priority Queue (Min-Heap Implementation)**
```pseudocode
STRUCTURE PriorityQueue
    heap: DynamicArray
    
    FUNCTION enqueue(element, priority)
        item ← CREATE PriorityItem(element, priority)
        heap.add(item)
        heapifyUp(heap.size - 1)
    END FUNCTION
    
    FUNCTION dequeue()
        IF isEmpty() THEN
            THROW QueueUnderflowException
        END IF
        
        min_item ← heap.get(0)
        last_item ← heap.get(heap.size - 1)
        heap.set(0, last_item)
        heap.removeAt(heap.size - 1)
        
        IF NOT isEmpty() THEN
            heapifyDown(0)
        END IF
        
        RETURN min_item.element
    END FUNCTION
    
    FUNCTION heapifyUp(index)
        WHILE index > 0 DO
            parent_index ← (index - 1) / 2
            IF heap.get(index).priority >= heap.get(parent_index).priority THEN
                BREAK
            END IF
            swap(heap, index, parent_index)
            index ← parent_index
        END WHILE
    END FUNCTION
    
    FUNCTION heapifyDown(index)
        WHILE true DO
            left_child ← 2 * index + 1
            right_child ← 2 * index + 2
            smallest ← index
            
            IF left_child < heap.size AND 
               heap.get(left_child).priority < heap.get(smallest).priority THEN
                smallest ← left_child
            END IF
            
            IF right_child < heap.size AND 
               heap.get(right_child).priority < heap.get(smallest).priority THEN
                smallest ← right_child
            END IF
            
            IF smallest = index THEN BREAK
            
            swap(heap, index, smallest)
            index ← smallest
        END WHILE
    END FUNCTION
END STRUCTURE
```

### 🌳 **1.2 Hierarchical Data Structures**

#### **🌲 Trees - Fundamental Concepts**

**Binary Tree Node**
```pseudocode
STRUCTURE TreeNode
    data: ElementType
    left: POINTER to TreeNode
    right: POINTER to TreeNode
    
    FUNCTION TreeNode(value)
        data ← value
        left ← NULL
        right ← NULL
    END FUNCTION
END STRUCTURE
```

**Tree Traversal Algorithms**
```pseudocode
// Depth-First Traversals
FUNCTION preorderTraversal(node)
    IF node ≠ NULL THEN
        visit(node.data)
        preorderTraversal(node.left)
        preorderTraversal(node.right)
    END IF
END FUNCTION

FUNCTION inorderTraversal(node)
    IF node ≠ NULL THEN
        inorderTraversal(node.left)
        visit(node.data)
        inorderTraversal(node.right)
    END IF
END FUNCTION

FUNCTION postorderTraversal(node)
    IF node ≠ NULL THEN
        postorderTraversal(node.left)
        postorderTraversal(node.right)
        visit(node.data)
    END IF
END FUNCTION

// Breadth-First Traversal
FUNCTION levelOrderTraversal(root)
    IF root = NULL THEN RETURN
    
    queue ← CREATE Queue
    queue.enqueue(root)
    
    WHILE NOT queue.isEmpty() DO
        node ← queue.dequeue()
        visit(node.data)
        
        IF node.left ≠ NULL THEN
            queue.enqueue(node.left)
        END IF
        
        IF node.right ≠ NULL THEN
            queue.enqueue(node.right)
        END IF
    END WHILE
END FUNCTION
```

#### **🔍 Binary Search Trees (BST)**

```pseudocode
STRUCTURE BinarySearchTree
    root: POINTER to TreeNode
    
    FUNCTION insert(value)
        root ← insertRecursive(root, value)
    END FUNCTION
    
    FUNCTION insertRecursive(node, value)
        IF node = NULL THEN
            RETURN CREATE TreeNode(value)
        END IF
        
        IF value < node.data THEN
            node.left ← insertRecursive(node.left, value)
        ELSIF value > node.data THEN
            node.right ← insertRecursive(node.right, value)
        END IF
        
        RETURN node
    END FUNCTION
    
    FUNCTION search(value)
        RETURN searchRecursive(root, value)
    END FUNCTION
    
    FUNCTION searchRecursive(node, value)
        IF node = NULL OR node.data = value THEN
            RETURN node
        END IF
        
        IF value < node.data THEN
            RETURN searchRecursive(node.left, value)
        ELSE
            RETURN searchRecursive(node.right, value)
        END IF
    END FUNCTION
    
    FUNCTION delete(value)
        root ← deleteRecursive(root, value)
    END FUNCTION
    
    FUNCTION deleteRecursive(node, value)
        IF node = NULL THEN RETURN NULL
        
        IF value < node.data THEN
            node.left ← deleteRecursive(node.left, value)
        ELSIF value > node.data THEN
            node.right ← deleteRecursive(node.right, value)
        ELSE
            // Node to be deleted found
            IF node.left = NULL THEN
                RETURN node.right
            ELSIF node.right = NULL THEN
                RETURN node.left
            ELSE
                // Node has two children
                successor ← findMin(node.right)
                node.data ← successor.data
                node.right ← deleteRecursive(node.right, successor.data)
            END IF
        END IF
        
        RETURN node
    END FUNCTION
    
    FUNCTION findMin(node)
        WHILE node.left ≠ NULL DO
            node ← node.left
        END WHILE
        RETURN node
    END FUNCTION
END STRUCTURE
```

#### **⚖️ AVL Trees (Self-Balancing BST)**

```pseudocode
STRUCTURE AVLNode
    data: ElementType
    left: POINTER to AVLNode
    right: POINTER to AVLNode
    height: INTEGER
END STRUCTURE

STRUCTURE AVLTree
    root: POINTER to AVLNode
    
    FUNCTION getHeight(node)
        IF node = NULL THEN RETURN 0
        RETURN node.height
    END FUNCTION
    
    FUNCTION getBalance(node)
        IF node = NULL THEN RETURN 0
        RETURN getHeight(node.left) - getHeight(node.right)
    END FUNCTION
    
    FUNCTION rotateRight(y)
        x ← y.left
        T2 ← x.right
        
        // Perform rotation
        x.right ← y
        y.left ← T2
        
        // Update heights
        y.height ← MAX(getHeight(y.left), getHeight(y.right)) + 1
        x.height ← MAX(getHeight(x.left), getHeight(x.right)) + 1
        
        RETURN x
    END FUNCTION
    
    FUNCTION rotateLeft(x)
        y ← x.right
        T2 ← y.left
        
        // Perform rotation
        y.left ← x
        x.right ← T2
        
        // Update heights
        x.height ← MAX(getHeight(x.left), getHeight(x.right)) + 1
        y.height ← MAX(getHeight(y.left), getHeight(y.right)) + 1
        
        RETURN y
    END FUNCTION
    
    FUNCTION insert(value)
        root ← insertAVL(root, value)
    END FUNCTION
    
    FUNCTION insertAVL(node, value)
        // Step 1: Normal BST insertion
        IF node = NULL THEN
            new_node ← CREATE AVLNode
            new_node.data ← value
            new_node.height ← 1
            RETURN new_node
        END IF
        
        IF value < node.data THEN
            node.left ← insertAVL(node.left, value)
        ELSIF value > node.data THEN
            node.right ← insertAVL(node.right, value)
        ELSE
            RETURN node // Duplicate values not allowed
        END IF
        
        // Step 2: Update height
        node.height ← 1 + MAX(getHeight(node.left), getHeight(node.right))
        
        // Step 3: Get balance factor
        balance ← getBalance(node)
        
        // Step 4: Perform rotations if unbalanced
        // Left Left Case
        IF balance > 1 AND value < node.left.data THEN
            RETURN rotateRight(node)
        END IF
        
        // Right Right Case
        IF balance < -1 AND value > node.right.data THEN
            RETURN rotateLeft(node)
        END IF
        
        // Left Right Case
        IF balance > 1 AND value > node.left.data THEN
            node.left ← rotateLeft(node.left)
            RETURN rotateRight(node)
        END IF
        
        // Right Left Case
        IF balance < -1 AND value < node.right.data THEN
            node.right ← rotateRight(node.right)
            RETURN rotateLeft(node)
        END IF
        
        RETURN node
    END FUNCTION
END STRUCTURE
```

### 🗺️ **1.3 Hash-Based Data Structures**

#### **🔐 Hash Tables**

```pseudocode
STRUCTURE HashEntry
    key: KeyType
    value: ValueType
    deleted: BOOLEAN
END STRUCTURE

STRUCTURE HashTable
    table: ARRAY of HashEntry
    size: INTEGER
    capacity: INTEGER
    
    FUNCTION HashTable(initial_capacity)
        capacity ← initial_capacity
        size ← 0
        table ← CREATE ARRAY[capacity] of HashEntry
    END FUNCTION
    
    FUNCTION hash(key)
        // Simple hash function (can be improved)
        hash_value ← 0
        FOR each character c in key DO
            hash_value ← (hash_value * 31 + ASCII(c)) MOD capacity
        END FOR
        RETURN hash_value
    END FUNCTION
    
    FUNCTION put(key, value)
        IF size >= capacity * 0.75 THEN
            resize()
        END IF
        
        index ← hash(key)
        original_index ← index
        
        WHILE table[index] ≠ NULL AND table[index].key ≠ key AND NOT table[index].deleted DO
            index ← (index + 1) MOD capacity
            IF index = original_index THEN
                THROW HashTableFullException
            END IF
        END WHILE
        
        IF table[index] = NULL OR table[index].deleted THEN
            size ← size + 1
        END IF
        
        table[index] ← CREATE HashEntry
        table[index].key ← key
        table[index].value ← value
        table[index].deleted ← false
    END FUNCTION
    
    FUNCTION get(key)
        index ← hash(key)
        original_index ← index
        
        WHILE table[index] ≠ NULL DO
            IF table[index].key = key AND NOT table[index].deleted THEN
                RETURN table[index].value
            END IF
            index ← (index + 1) MOD capacity
            IF index = original_index THEN
                BREAK
            END IF
        END WHILE
        
        THROW KeyNotFoundException
    END FUNCTION
    
    FUNCTION remove(key)
        index ← hash(key)
        original_index ← index
        
        WHILE table[index] ≠ NULL DO
            IF table[index].key = key AND NOT table[index].deleted THEN
                table[index].deleted ← true
                size ← size - 1
                RETURN true
            END IF
            index ← (index + 1) MOD capacity
            IF index = original_index THEN
                BREAK
            END IF
        END WHILE
        
        RETURN false
    END FUNCTION
END STRUCTURE
```

---

## ⚡ 2. ALGORITHMIC COMPLEXITY ANALYSIS

### 📊 **2.1 Asymptotic Notation**

#### **Big O Notation (Upper Bound)**
- **Definition:** f(n) = O(g(n)) if there exist positive constants c and n₀ such that f(n) ≤ c·g(n) for all n ≥ n₀
- **Interpretation:** f(n) grows no faster than g(n)

#### **Big Omega Notation (Lower Bound)**
- **Definition:** f(n) = Ω(g(n)) if there exist positive constants c and n₀ such that f(n) ≥ c·g(n) for all n ≥ n₀
- **Interpretation:** f(n) grows at least as fast as g(n)

#### **Big Theta Notation (Tight Bound)**
- **Definition:** f(n) = Θ(g(n)) if f(n) = O(g(n)) and f(n) = Ω(g(n))
- **Interpretation:** f(n) grows at the same rate as g(n)

#### **Common Growth Rates (from slowest to fastest)**
1. **O(1)** - Constant
2. **O(log n)** - Logarithmic
3. **O(n)** - Linear
4. **O(n log n)** - Linearithmic
5. **O(n²)** - Quadratic
6. **O(n³)** - Cubic
7. **O(2ⁿ)** - Exponential
8. **O(n!)** - Factorial

### 📈 **2.2 Complexity Analysis Techniques**

#### **Master Theorem**
For recurrences of the form: T(n) = aT(n/b) + f(n)

**Case 1:** If f(n) = O(n^(log_b(a) - ε)) for some ε > 0, then T(n) = Θ(n^log_b(a))

**Case 2:** If f(n) = Θ(n^log_b(a)), then T(n) = Θ(n^log_b(a) · log n)

**Case 3:** If f(n) = Ω(n^(log_b(a) + ε)) for some ε > 0, and af(n/b) ≤ cf(n) for some c < 1, then T(n) = Θ(f(n))

#### **Examples:**
```pseudocode
// T(n) = 2T(n/2) + O(n) - Merge Sort
// a = 2, b = 2, f(n) = n
// log_2(2) = 1, so f(n) = Θ(n^1) = Θ(n)
// Case 2: T(n) = Θ(n log n)

// T(n) = 2T(n/2) + O(1) - Binary Search
// a = 2, b = 2, f(n) = 1
// log_2(2) = 1, f(n) = O(n^0) = O(1)
// Case 1: T(n) = Θ(n^1) = Θ(n)
```

### 🔍 **2.3 Amortized Analysis**

#### **Aggregate Method**
Calculate the total cost of n operations and divide by n.

#### **Accounting Method**
Assign different charges to different operations, some more than actual cost, some less.

#### **Potential Method**
Define a potential function that captures the "stored energy" in the data structure.

**Example: Dynamic Array Resizing**
```pseudocode
FUNCTION analyzeDynamicArrayInsertion(n)
    total_cost ← 0
    
    FOR i ← 1 TO n DO
        IF i is a power of 2 THEN
            // Resize operation costs O(i)
            total_cost ← total_cost + i
        ELSE
            // Regular insertion costs O(1)
            total_cost ← total_cost + 1
        END IF
    END FOR
    
    // Total cost is O(n), so amortized cost per operation is O(1)
    RETURN total_cost / n
END FUNCTION
```

---

## 🧩 3. FUNDAMENTAL ALGORITHMS

### 🔍 **3.1 Searching Algorithms**

#### **Linear Search**
```pseudocode
FUNCTION linearSearch(array, target)
    FOR i ← 0 TO length(array) - 1 DO
        IF array[i] = target THEN
            RETURN i
        END IF
    END FOR
    RETURN -1
END FUNCTION
```
- **Time Complexity:** O(n)
- **Space Complexity:** O(1)

#### **Binary Search**
```pseudocode
FUNCTION binarySearch(sorted_array, target)
    left ← 0
    right ← length(sorted_array) - 1
    
    WHILE left ≤ right DO
        mid ← left + (right - left) / 2
        
        IF sorted_array[mid] = target THEN
            RETURN mid
        ELSIF sorted_array[mid] < target THEN
            left ← mid + 1
        ELSE
            right ← mid - 1
        END IF
    END WHILE
    
    RETURN -1
END FUNCTION
```
- **Time Complexity:** O(log n)
- **Space Complexity:** O(1)

#### **Ternary Search**
```pseudocode
FUNCTION ternarySearch(sorted_array, target, left, right)
    IF left > right THEN RETURN -1
    
    mid1 ← left + (right - left) / 3
    mid2 ← right - (right - left) / 3
    
    IF sorted_array[mid1] = target THEN RETURN mid1
    IF sorted_array[mid2] = target THEN RETURN mid2
    
    IF target < sorted_array[mid1] THEN
        RETURN ternarySearch(sorted_array, target, left, mid1 - 1)
    ELSIF target > sorted_array[mid2] THEN
        RETURN ternarySearch(sorted_array, target, mid2 + 1, right)
    ELSE
        RETURN ternarySearch(sorted_array, target, mid1 + 1, mid2 - 1)
    END IF
END FUNCTION
```
- **Time Complexity:** O(log₃ n)
- **Space Complexity:** O(log n) due to recursion

### 📊 **3.2 Sorting Algorithms**

#### **Bubble Sort**
```pseudocode
FUNCTION bubbleSort(array)
    n ← length(array)
    
    FOR i ← 0 TO n - 2 DO
        swapped ← false
        FOR j ← 0 TO n - i - 2 DO
            IF array[j] > array[j + 1] THEN
                swap(array[j], array[j + 1])
                swapped ← true
            END IF
        END FOR
        IF NOT swapped THEN BREAK
    END FOR
END FUNCTION
```
- **Time Complexity:** O(n²) worst/average, O(n) best
- **Space Complexity:** O(1)
- **Stable:** Yes

#### **Selection Sort**
```pseudocode
FUNCTION selectionSort(array)
    n ← length(array)
    
    FOR i ← 0 TO n - 2 DO
        min_index ← i
        FOR j ← i + 1 TO n - 1 DO
            IF array[j] < array[min_index] THEN
                min_index ← j
            END IF
        END FOR
        swap(array[i], array[min_index])
    END FOR
END FUNCTION
```
- **Time Complexity:** O(n²) all cases
- **Space Complexity:** O(1)
- **Stable:** No

#### **Insertion Sort**
```pseudocode
FUNCTION insertionSort(array)
    FOR i ← 1 TO length(array) - 1 DO
        key ← array[i]
        j ← i - 1
        
        WHILE j ≥ 0 AND array[j] > key DO
            array[j + 1] ← array[j]
            j ← j - 1
        END WHILE
        
        array[j + 1] ← key
    END FOR
END FUNCTION
```
- **Time Complexity:** O(n²) worst/average, O(n) best
- **Space Complexity:** O(1)
- **Stable:** Yes

#### **Merge Sort**
```pseudocode
FUNCTION mergeSort(array, left, right)
    IF left < right THEN
        mid ← left + (right - left) / 2
        
        mergeSort(array, left, mid)
        mergeSort(array, mid + 1, right)
        merge(array, left, mid, right)
    END IF
END FUNCTION

FUNCTION merge(array, left, mid, right)
    left_size ← mid - left + 1
    right_size ← right - mid
    
    left_array ← CREATE ARRAY[left_size]
    right_array ← CREATE ARRAY[right_size]
    
    FOR i ← 0 TO left_size - 1 DO
        left_array[i] ← array[left + i]
    END FOR
    
    FOR j ← 0 TO right_size - 1 DO
        right_array[j] ← array[mid + 1 + j]
    END FOR
    
    i ← 0, j ← 0, k ← left
    
    WHILE i < left_size AND j < right_size DO
        IF left_array[i] ≤ right_array[j] THEN
            array[k] ← left_array[i]
            i ← i + 1
        ELSE
            array[k] ← right_array[j]
            j ← j + 1
        END IF
        k ← k + 1
    END WHILE
    
    WHILE i < left_size DO
        array[k] ← left_array[i]
        i ← i + 1
        k ← k + 1
    END WHILE
    
    WHILE j < right_size DO
        array[k] ← right_array[j]
        j ← j + 1
        k ← k + 1
    END WHILE
END FUNCTION
```
- **Time Complexity:** O(n log n) all cases
- **Space Complexity:** O(n)
- **Stable:** Yes

#### **Quick Sort**
```pseudocode
FUNCTION quickSort(array, low, high)
    IF low < high THEN
        partition_index ← partition(array, low, high)
        quickSort(array, low, partition_index - 1)
        quickSort(array, partition_index + 1, high)
    END IF
END FUNCTION

FUNCTION partition(array, low, high)
    pivot ← array[high]
    i ← low - 1
    
    FOR j ← low TO high - 1 DO
        IF array[j] < pivot THEN
            i ← i + 1
            swap(array[i], array[j])
        END IF
    END FOR
    
    swap(array[i + 1], array[high])
    RETURN i + 1
END FUNCTION
```
- **Time Complexity:** O(n²) worst, O(n log n) average/best
- **Space Complexity:** O(log n) average, O(n) worst
- **Stable:** No

#### **Heap Sort**
```pseudocode
FUNCTION heapSort(array)
    n ← length(array)
    
    // Build max heap
    FOR i ← n/2 - 1 DOWN TO 0 DO
        heapify(array, n, i)
    END FOR
    
    // Extract elements from heap one by one
    FOR i ← n - 1 DOWN TO 1 DO
        swap(array[0], array[i])
        heapify(array, i, 0)
    END FOR
END FUNCTION

FUNCTION heapify(array, n, i)
    largest ← i
    left ← 2 * i + 1
    right ← 2 * i + 2
    
    IF left < n AND array[left] > array[largest] THEN
        largest ← left
    END IF
    
    IF right < n AND array[right] > array[largest] THEN
        largest ← right
    END IF
    
    IF largest ≠ i THEN
        swap(array[i], array[largest])
        heapify(array, n, largest)
    END IF
END FUNCTION
```
- **Time Complexity:** O(n log n) all cases
- **Space Complexity:** O(1)
- **Stable:** No

---

## 🎨 4. ALGORITHMIC PARADIGMS

### 🔄 **4.1 Divide and Conquer**

#### **Key Principles:**
1. **Divide:** Break problem into smaller subproblems
2. **Conquer:** Solve subproblems recursively
3. **Combine:** Merge solutions to solve original problem

#### **Example: Maximum Subarray Problem**
```pseudocode
FUNCTION maxSubarraySum(array, low, high)
    IF low = high THEN
        RETURN array[low]
    END IF
    
    mid ← (low + high) / 2
    
    left_sum ← maxSubarraySum(array, low, mid)
    right_sum ← maxSubarraySum(array, mid + 1, high)
    cross_sum ← maxCrossingSum(array, low, mid, high)
    
    RETURN max(left_sum, right_sum, cross_sum)
END FUNCTION

FUNCTION maxCrossingSum(array, low, mid, high)
    left_sum ← -INFINITY
    sum ← 0
    
    FOR i ← mid DOWN TO low DO
        sum ← sum + array[i]
        IF sum > left_sum THEN
            left_sum ← sum
        END IF
    END FOR
    
    right_sum ← -INFINITY
    sum ← 0
    
    FOR i ← mid + 1 TO high DO
        sum ← sum + array[i]
        IF sum > right_sum THEN
            right_sum ← sum
        END IF
    END FOR
    
    RETURN left_sum + right_sum
END FUNCTION
```

### 🎯 **4.2 Greedy Algorithms**

#### **Key Principles:**
1. Make locally optimal choice at each step
2. Hope that local optimum leads to global optimum
3. Never reconsider previous choices

#### **Example: Activity Selection Problem**
```pseudocode
FUNCTION activitySelection(activities)
    // Sort activities by finish time
    sort(activities, BY finish_time)
    
    selected ← CREATE List
    selected.add(activities[0])
    last_selected ← 0
    
    FOR i ← 1 TO length(activities) - 1 DO
        IF activities[i].start_time ≥ activities[last_selected].finish_time THEN
            selected.add(activities[i])
            last_selected ← i
        END IF
    END FOR
    
    RETURN selected
END FUNCTION
```

#### **Example: Huffman Coding**
```pseudocode
STRUCTURE HuffmanNode
    character: CHAR
    frequency: INTEGER
    left: POINTER to HuffmanNode
    right: POINTER to HuffmanNode
END STRUCTURE

FUNCTION buildHuffmanTree(characters, frequencies)
    priority_queue ← CREATE MinPriorityQueue
    
    // Create leaf nodes and add to priority queue
    FOR i ← 0 TO length(characters) - 1 DO
        node ← CREATE HuffmanNode
        node.character ← characters[i]
        node.frequency ← frequencies[i]
        priority_queue.enqueue(node, frequencies[i])
    END FOR
    
    // Build tree bottom-up
    WHILE priority_queue.size() > 1 DO
        left ← priority_queue.dequeue()
        right ← priority_queue.dequeue()
        
        merged ← CREATE HuffmanNode
        merged.frequency ← left.frequency + right.frequency
        merged.left ← left
        merged.right ← right
        
        priority_queue.enqueue(merged, merged.frequency)
    END WHILE
    
    RETURN priority_queue.dequeue()
END FUNCTION
```

### 🧮 **4.3 Dynamic Programming**

#### **Key Principles:**
1. **Optimal Substructure:** Optimal solution contains optimal solutions to subproblems
2. **Overlapping Subproblems:** Same subproblems are solved multiple times
3. **Memoization:** Store solutions to avoid recomputation

#### **Example: Fibonacci with Memoization**
```pseudocode
memo ← CREATE Map

FUNCTION fibonacci(n)
    IF n ≤ 1 THEN RETURN n
    
    IF memo.contains(n) THEN
        RETURN memo.get(n)
    END IF
    
    result ← fibonacci(n - 1) + fibonacci(n - 2)
    memo.put(n, result)
    RETURN result
END FUNCTION
```

#### **Example: 0/1 Knapsack Problem**
```pseudocode
FUNCTION knapsack(weights, values, capacity, n)
    // Create DP table
    dp ← CREATE 2D_ARRAY[n + 1][capacity + 1]
    
    // Initialize base cases
    FOR i ← 0 TO n DO
        dp[i][0] ← 0
    END FOR
    
    FOR w ← 0 TO capacity DO
        dp[0][w] ← 0
    END FOR
    
    // Fill DP table
    FOR i ← 1 TO n DO
        FOR w ← 1 TO capacity DO
            IF weights[i - 1] ≤ w THEN
                // Include or exclude current item
                include ← values[i - 1] + dp[i - 1][w - weights[i - 1]]
                exclude ← dp[i - 1][w]
                dp[i][w] ← max(include, exclude)
            ELSE
                dp[i][w] ← dp[i - 1][w]
            END IF
        END FOR
    END FOR
    
    RETURN dp[n][capacity]
END FUNCTION
```

#### **Example: Longest Common Subsequence**
```pseudocode
FUNCTION longestCommonSubsequence(text1, text2)
    m ← length(text1)
    n ← length(text2)
    dp ← CREATE 2D_ARRAY[m + 1][n + 1]
    
    // Initialize base cases
    FOR i ← 0 TO m DO
        dp[i][0] ← 0
    END FOR
    
    FOR j ← 0 TO n DO
        dp[0][j] ← 0
    END FOR
    
    // Fill DP table
    FOR i ← 1 TO m DO
        FOR j ← 1 TO n DO
            IF text1[i - 1] = text2[j - 1] THEN
                dp[i][j] ← dp[i - 1][j - 1] + 1
            ELSE
                dp[i][j] ← max(dp[i - 1][j], dp[i][j - 1])
            END IF
        END FOR
    END FOR
    
    RETURN dp[m][n]
END FUNCTION
```

### 🔍 **4.4 Backtracking**

#### **Key Principles:**
1. Build solution incrementally
2. Abandon candidates ("backtrack") when they cannot lead to valid solution
3. Use recursion to explore search space

#### **Example: N-Queens Problem**
```pseudocode
FUNCTION solveNQueens(n)
    board ← CREATE 2D_ARRAY[n][n] initialized with false
    solutions ← CREATE List
    
    solveNQueensUtil(board, 0, n, solutions)
    RETURN solutions
END FUNCTION

FUNCTION solveNQueensUtil(board, col, n, solutions)
    IF col ≥ n THEN
        // All queens placed successfully
        solutions.add(copyBoard(board))
        RETURN
    END IF
    
    FOR row ← 0 TO n - 1 DO
        IF isSafe(board, row, col, n) THEN
            board[row][col] ← true
            solveNQueensUtil(board, col + 1, n, solutions)
            board[row][col] ← false // Backtrack
        END IF
    END FOR
END FUNCTION

FUNCTION isSafe(board, row, col, n)
    // Check row on left side
    FOR i ← 0 TO col - 1 DO
        IF board[row][i] THEN RETURN false
    END FOR
    
    // Check upper diagonal on left side
    i ← row - 1
    j ← col - 1
    WHILE i ≥ 0 AND j ≥ 0 DO
        IF board[i][j] THEN RETURN false
        i ← i - 1
        j ← j - 1
    END WHILE
    
    // Check lower diagonal on left side
    i ← row + 1
    j ← col - 1
    WHILE i < n AND j ≥ 0 DO
        IF board[i][j] THEN RETURN false
        i ← i + 1
        j ← j - 1
    END WHILE
    
    RETURN true
END FUNCTION
```

---

## 🌐 5. GRAPH ALGORITHMS

### 📊 **5.1 Graph Representation**

#### **Adjacency Matrix**
```pseudocode
STRUCTURE GraphMatrix
    matrix: 2D_ARRAY[V][V] of BOOLEAN
    vertices: INTEGER
    
    FUNCTION addEdge(u, v)
        matrix[u][v] ← true
        matrix[v][u] ← true // For undirected graph
    END FUNCTION
    
    FUNCTION hasEdge(u, v)
        RETURN matrix[u][v]
    END FUNCTION
END STRUCTURE
```

#### **Adjacency List**
```pseudocode
STRUCTURE GraphList
    adjacency_list: ARRAY[V] of List
    vertices: INTEGER
    
    FUNCTION addEdge(u, v)
        adjacency_list[u].add(v)
        adjacency_list[v].add(u) // For undirected graph
    END FUNCTION
    
    FUNCTION getNeighbors(u)
        RETURN adjacency_list[u]
    END FUNCTION
END STRUCTURE
```

### 🔍 **5.2 Graph Traversal**

#### **Depth-First Search (DFS)**
```pseudocode
FUNCTION dfs(graph, start_vertex)
    visited ← CREATE Set
    dfsUtil(graph, start_vertex, visited)
END FUNCTION

FUNCTION dfsUtil(graph, vertex, visited)
    visited.add(vertex)
    visit(vertex)
    
    FOR each neighbor in graph.getNeighbors(vertex) DO
        IF NOT visited.contains(neighbor) THEN
            dfsUtil(graph, neighbor, visited)
        END IF
    END FOR
END FUNCTION
```

#### **Breadth-First Search (BFS)**
```pseudocode
FUNCTION bfs(graph, start_vertex)
    visited ← CREATE Set
    queue ← CREATE Queue
    
    visited.add(start_vertex)
    queue.enqueue(start_vertex)
    
    WHILE NOT queue.isEmpty() DO
        vertex ← queue.dequeue()
        visit(vertex)
        
        FOR each neighbor in graph.getNeighbors(vertex) DO
            IF NOT visited.contains(neighbor) THEN
                visited.add(neighbor)
                queue.enqueue(neighbor)
            END IF
        END FOR
    END WHILE
END FUNCTION
```

### 🛤️ **5.3 Shortest Path Algorithms**

#### **Dijkstra's Algorithm**
```pseudocode
FUNCTION dijkstra(graph, source)
    distances ← CREATE Map initialized with INFINITY
    previous ← CREATE Map
    priority_queue ← CREATE MinPriorityQueue
    
    distances[source] ← 0
    priority_queue.enqueue(source, 0)
    
    WHILE NOT priority_queue.isEmpty() DO
        current ← priority_queue.dequeue()
        
        FOR each neighbor, weight in graph.getNeighbors(current) DO
            alternative ← distances[current] + weight
            
            IF alternative < distances[neighbor] THEN
                distances[neighbor] ← alternative
                previous[neighbor] ← current
                priority_queue.enqueue(neighbor, alternative)
            END IF
        END FOR
    END WHILE
    
    RETURN distances, previous
END FUNCTION
```

#### **Bellman-Ford Algorithm**
```pseudocode
FUNCTION bellmanFord(graph, source)
    distances ← CREATE Map initialized with INFINITY
    distances[source] ← 0
    
    // Relax edges repeatedly
    FOR i ← 1 TO graph.vertices - 1 DO
        FOR each edge (u, v, weight) in graph.edges DO
            IF distances[u] ≠ INFINITY AND distances[u] + weight < distances[v] THEN
                distances[v] ← distances[u] + weight
            END IF
        END FOR
    END FOR
    
    // Check for negative-weight cycles
    FOR each edge (u, v, weight) in graph.edges DO
        IF distances[u] ≠ INFINITY AND distances[u] + weight < distances[v] THEN
            THROW NegativeCycleException
        END IF
    END FOR
    
    RETURN distances
END FUNCTION
```

### 🌳 **5.4 Minimum Spanning Tree**

#### **Kruskal's Algorithm**
```pseudocode
STRUCTURE Edge
    source: INTEGER
    destination: INTEGER
    weight: INTEGER
END STRUCTURE

FUNCTION kruskalMST(graph)
    result ← CREATE List
    edges ← graph.getAllEdges()
    sort(edges, BY weight)
    
    union_find ← CREATE UnionFind(graph.vertices)
    
    FOR each edge in edges DO
        IF union_find.find(edge.source) ≠ union_find.find(edge.destination) THEN
            result.add(edge)
            union_find.union(edge.source, edge.destination)
            
            IF result.size() = graph.vertices - 1 THEN
                BREAK
            END IF
        END IF
    END FOR
    
    RETURN result
END FUNCTION
```

#### **Prim's Algorithm**
```pseudocode
FUNCTION primMST(graph, start_vertex)
    mst_edges ← CREATE List
    visited ← CREATE Set
    priority_queue ← CREATE MinPriorityQueue
    
    visited.add(start_vertex)
    
    FOR each neighbor, weight in graph.getNeighbors(start_vertex) DO
        priority_queue.enqueue((start_vertex, neighbor, weight), weight)
    END FOR
    
    WHILE NOT priority_queue.isEmpty() AND visited.size() < graph.vertices DO
        edge ← priority_queue.dequeue()
        source, destination, weight ← edge
        
        IF NOT visited.contains(destination) THEN
            visited.add(destination)
            mst_edges.add(edge)
            
            FOR each neighbor, weight in graph.getNeighbors(destination) DO
                IF NOT visited.contains(neighbor) THEN
                    priority_queue.enqueue((destination, neighbor, weight), weight)
                END IF
            END FOR
        END IF
    END WHILE
    
    RETURN mst_edges
END FUNCTION
```

---

## 🛠️ 6. PRACTICAL APPLICATIONS AND PROJECTS

### 🎯 **6.1 Data Structure Selection Guide**

#### **Array vs Linked List**
- **Use Array when:**
  - Random access needed (O(1) access by index)
  - Memory usage is a concern
  - Cache performance is important
  
- **Use Linked List when:**
  - Frequent insertions/deletions at arbitrary positions
  - Size varies dramatically
  - Memory is allocated dynamically

#### **Stack vs Queue Applications**
- **Stack Applications:**
  - Function call management
  - Expression evaluation
  - Undo operations
  - Backtracking algorithms
  
- **Queue Applications:**
  - Process scheduling
  - BFS traversal
  - Buffer for data streams
  - Print job management

#### **BST vs Hash Table**
- **Use BST when:**
  - Need sorted order
  - Range queries required
  - Predictable performance needed
  
- **Use Hash Table when:**
  - Fast lookup is priority
  - No ordering required
  - Average case performance is acceptable

### 💻 **6.2 Implementation Projects**

#### **Project 1: Custom Collections Library**
Implement a comprehensive collections library including:
- Dynamic Array with automatic resizing
- Doubly Linked List with iterator support
- Stack and Queue implementations
- Hash Table with collision resolution
- Binary Search Tree with balancing

#### **Project 2: Algorithm Visualizer**
Create a visual tool that demonstrates:
- Sorting algorithm animations
- Graph traversal visualization
- Tree operations display
- Complexity analysis charts

#### **Project 3: Text Processing Engine**
Build a system that uses multiple data structures:
- Trie for autocomplete functionality
- Hash table for word frequency counting
- Priority queue for top-k frequent words
- Suffix tree for pattern matching

#### **Project 4: Graph Analysis Tool**
Develop an application for:
- Social network analysis
- Shortest path finding
- Community detection
- Network flow optimization

---

## 📊 7. PERFORMANCE OPTIMIZATION TECHNIQUES

### ⚡ **7.1 Algorithm Optimization Strategies**

#### **Space-Time Tradeoffs**
- **Memoization:** Trade space for time in recursive algorithms
- **Lookup Tables:** Precompute values to avoid repeated calculations
- **Caching:** Store frequently accessed data

#### **Example: Matrix Chain Multiplication**
```pseudocode
FUNCTION matrixChainOrder(dimensions)
    n ← length(dimensions) - 1
    dp ← CREATE 2D_ARRAY[n][n]
    
    // l is chain length
    FOR l ← 2 TO n DO
        FOR i ← 0 TO n - l DO
            j ← i + l - 1
            dp[i][j] ← INFINITY
            
            FOR k ← i TO j - 1 DO
                cost ← dp[i][k] + dp[k + 1][j] + 
                       dimensions[i] * dimensions[k + 1] * dimensions[j + 1]
                IF cost < dp[i][j] THEN
                    dp[i][j] ← cost
                END IF
            END FOR
        END FOR
    END FOR
    
    RETURN dp[0][n - 1]
END FUNCTION
```

### 🎯 **7.2 Code Optimization Techniques**

#### **Loop Optimization**
```pseudocode
// Inefficient - repeated function calls
FOR i ← 0 TO getArrayLength() - 1 DO
    process(array[i])
END FOR

// Optimized - cache length
length ← getArrayLength()
FOR i ← 0 TO length - 1 DO
    process(array[i])
END FOR
```

#### **Memory Access Optimization**
```pseudocode
// Cache-friendly matrix multiplication
FUNCTION efficientMatrixMultiply(A, B, C, n)
    FOR i ← 0 TO n - 1 DO
        FOR k ← 0 TO n - 1 DO
            r ← A[i][k]
            FOR j ← 0 TO n - 1 DO
                C[i][j] ← C[i][j] + r * B[k][j]
            END FOR
        END FOR
    END FOR
END FUNCTION
```

---

## 📚 8. ADVANCED TOPICS PREVIEW

### 🌟 **8.1 Advanced Data Structures**
- **B-Trees:** Multi-way search trees for databases
- **Red-Black Trees:** Self-balancing BST with guaranteed O(log n)
- **Segment Trees:** Range query optimization
- **Fenwick Trees:** Efficient prefix sum queries
- **Disjoint Set (Union-Find):** Connected components

### 🧠 **8.2 Advanced Algorithms**
- **Network Flow:** Maximum flow algorithms
- **String Algorithms:** KMP, Rabin-Karp, suffix arrays
- **Computational Geometry:** Convex hull, line intersection
- **Approximation Algorithms:** Solutions for NP-hard problems
- **Randomized Algorithms:** Monte Carlo and Las Vegas methods

---

## ✅ 9. SELF-ASSESSMENT AND PRACTICE

### 🎯 **9.1 Skill Assessment Checklist**

#### **Data Structures Mastery**
- [ ] Can implement arrays, linked lists, stacks, and queues from scratch
- [ ] Understand tree traversals and BST operations
- [ ] Can design and implement hash tables with collision resolution
- [ ] Familiar with heap operations and priority queues
- [ ] Understand graph representations and basic operations

#### **Algorithm Analysis**
- [ ] Can analyze time and space complexity using Big O notation
- [ ] Understand amortized analysis concepts
- [ ] Can apply Master Theorem to divide-and-conquer recurrences
- [ ] Familiar with best, average, and worst-case analysis

#### **Problem-Solving Skills**
- [ ] Can choose appropriate data structures for given problems
- [ ] Understand when to apply different algorithmic paradigms
- [ ] Can optimize algorithms for specific constraints
- [ ] Capable of designing original algorithms for novel problems

### 🏆 **9.2 Practice Problem Categories**

#### **Easy Level (Warm-up)**
1. Implement basic data structures
2. Simple sorting and searching
3. Basic tree traversals
4. Elementary graph problems

#### **Medium Level (Skill Building)**
1. Dynamic programming problems
2. Complex tree operations
3. Graph algorithms (DFS, BFS, shortest path)
4. Advanced sorting algorithms

#### **Hard Level (Mastery)**
1. Complex optimization problems
2. Advanced graph algorithms
3. Challenging dynamic programming
4. Algorithm design challenges

---

## 📖 10. RESOURCES AND CONTINUED LEARNING

### 📚 **Essential References**
- **"Introduction to Algorithms"** by Cormen, Leiserson, Rivest, and Stein (CLRS)
- **"The Algorithm Design Manual"** by Steven Skiena
- **"Algorithms"** by Robert Sedgewick and Kevin Wayne
- **"Data Structures and Algorithms in Java"** by Michael Goodrich

### 🌐 **Online Platforms**
- **LeetCode:** Algorithm practice with company-specific problems
- **HackerRank:** Comprehensive programming challenges
- **Codeforces:** Competitive programming platform
- **AtCoder:** Japanese competitive programming site
- **TopCoder:** Algorithm competitions and practice

### 🎥 **Video Resources**
- **MIT 6.006:** Introduction to Algorithms
- **Stanford CS161:** Design and Analysis of Algorithms
- **Princeton Algorithms:** Coursera specialization
- **GeeksforGeeks:** Comprehensive tutorials and examples

### 🛠️ **Tools and Simulators**
- **VisuAlgo:** Algorithm visualization tool
- **Data Structure Visualizations:** University of San Francisco
- **Algorithm Visualizer:** Interactive algorithm demonstrations
- **Sorting Visualizer:** Compare sorting algorithm performance

---

## 🎯 FINAL RECOMMENDATIONS

### 🚀 **Success Strategies**
1. **Practice Regularly:** Solve problems daily to maintain and improve skills
2. **Understand, Don't Memorize:** Focus on underlying principles rather than rote learning
3. **Implement from Scratch:** Build data structures and algorithms without libraries
4. **Analyze Complexity:** Always consider time and space requirements
5. **Test Thoroughly:** Include edge cases and stress testing in your practice

### 🎪 **Next Steps**
Upon mastering these fundamentals, you'll be well-prepared for:
- **Advanced Algorithm Design:** Tackling complex computational problems
- **System Design:** Understanding performance implications at scale
- **Competitive Programming:** Participating in programming contests
- **Technical Interviews:** Succeeding in software engineering interviews
- **Research:** Contributing to algorithmic research and development

---

*🌟 Remember: Mastery of algorithms and data structures is not just about memorizing implementations—it's about developing the analytical thinking and problem-solving skills that will serve you throughout your entire career in computer science.*

---

*🚀 Next: [Programming Paradigms and Languages](../02-Programming-Paradigms/2-Programming-Paradigms.md)*
